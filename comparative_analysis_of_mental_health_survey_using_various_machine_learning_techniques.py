# -*- coding: utf-8 -*-
"""Comparative Analysis of Mental Health Survey Using Various Machine Learning Techniques.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iSDE-4v_GR2EabJIJs-3c1c61npgfliq
"""

pip install streamlit

from logging import root
import streamlit as st
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from sklearn import preprocessing
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.model_selection import KFold, cross_val_score
import math

kf = KFold(n_splits=10, random_state=0, shuffle=True)



df = pd.read_csv('/content/survey.csv')
print("The dimensions of uploaded CSV are :", df.shape)
print("The uploaded CSV is :", df.head())

df.head()

# defaults
defaultInt = 0
defaultString = 'NaN'
defaultFloat = 0.0

if 'Gender' or 'gender' in df.columns:
    if False:
        df.isnull().sum().sort_values(ascending=False)
        male = ['male', 'Male', 'M', 'm', 'Male-ish', 'maile', 'Cis Male', 'Mal', 'Male (CIS)', 'Make', 'Male ', 'Man',
                'msle', 'Mail', 'cis male', 'Malr', 'Cis Man']
        female = ['Female', 'female', 'Cis Female', 'F', 'Woman', 'f', 'Femake', 'woman', 'Female ', 'cis-female/femme',
                  'Female (cis)', 'femail']
        other = ['Trans-female', 'something kinda male?', 'queer/she/they', 'non-binary', 'Nah', 'All', 'Enby', 'fluid',
                 'Genderqueer', 'Androgyne', 'Agender', 'Guy (-ish) ^_^', 'male leaning androgynous', 'Trans woman',
                 'Neuter', 'Female (trans)', 'queer', 'ostensibly male, unsure what that really means']
        dropped = ['A little about you', 'p']
        df = df[(df['Gender'] != 'A little about you') & (df['Gender'] != 'p')]
        df.replace(to_replace=male, value='male', inplace=True)
        df.replace(to_replace=other, value='other', inplace=True)
        df.replace(to_replace=female, value='female', inplace=True)

if 'comments' in df.columns:
    df = df.drop(['comments'], axis= 1)

if 'state' in df.columns:
    df = df.drop(['state'], axis= 1)

if 'Timestamp' in df.columns:
    df = df.drop(['Timestamp'], axis= 1)

# Sorting bi-variate df values

if 'Age' or 'age' in df.columns:
    if False:
        df['Age'].fillna(df['Age'].median(), inplace=True)

        # Fill with media() values < 18 and > 120
        s = pd.Series(df['Age'])
        s[s < 18] = df['Age'].median()
        df['Age'] = s
        s = pd.Series(df['Age'])
        s[s > 120] = df['Age'].median()
        df['Age'] = s

        # Ranges of Age
        df['age_range'] = pd.cut(df['Age'], [0, 20, 30, 65, 100], labels=["0-20", "21-30", "31-65", "66-100"],
                                 include_lowest=True)
        df['self_employed'] = df['self_employed'].replace([defaultString], 'No')
        df['work_interfere'] = df['work_interfere'].replace([defaultString], 'Don\'t know')
        df = df.drop(['Country'], axis=1)

labelDict = {}
for feature in df:
    le = preprocessing.LabelEncoder()
    le.fit(df[feature])
    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
    df[feature] = le.transform(df[feature])
    # Get labels
    labelKey = 'label_' + feature
    labelValue = [*le_name_mapping]
    labelDict[labelKey] = labelValue

df.head()

cols = df.columns

encoder = LabelEncoder()
for col in cols:
    encoder.fit(df[col])
    df[col] = encoder.transform(df[col])

plt.figure(figsize = (16, 10), dpi = 100)

corr = df.corr()

mask = np.zeros_like(corr, dtype=np.bool_)
mask[np.triu_indices_from(mask)] = True


# corr figure plot(Bar graph)
fig, ax = plt.subplots()
sns.heatmap(df.corr(), ax=ax)
st.write(fig)

fig ,ax = plt.subplots(figsize=(20,5))
Xaxis = df.Gender
Yaxis = df.phys_health_interview
sns.barplot(x = Xaxis, y = Yaxis, ax = ax)

z = int(input(' Enter the Training/Test data split value'))
X=df.iloc[:,:-1].values
y=df.iloc[:,1].values

x_true, x_pred, y_true, y_pred = train_test_split(X,y,test_size=z, random_state=10)

def create_linear_regression_model():
    from sklearn.linear_model import LinearRegression
    from sklearn import metrics
    regressor = LinearRegression()
    regressor.fit(x_true, y_true)
    accuracy=regressor.score(x_true, y_true)
    print("R2 Score - ", accuracy)
    y_pred_sk = regressor.predict(x_true)
    mse = metrics.mean_squared_error(y_true,y_pred_sk)
    print("Mean Squared Error - ", mse)
    rmse = math.sqrt(mse)
    print("Root Mean Squared Error - ", rmse)
    return LinearRegression()

def create_logistic_regression_model():
    from sklearn.linear_model import LogisticRegression
    from sklearn import metrics
    LL = LogisticRegression()
    LL.fit(x_true, y_true)
    LL_pred = LL.predict(x_pred)
    LL_train = LL.predict(x_true)
    accuracy = accuracy_score(y_true, LL_train)
    s = metrics.confusion_matrix(y_pred, LL_pred)
    print("Accuracy - ", accuracy)
    accuracy2 = accuracy_score(y_pred, LL_pred)
    print("Confusion Matrix for pred Value - ", s)
    fig, ax = plt.subplots()
    sns.heatmap(s, ax = ax)
    st.write(fig)
    df = (classification_report(y_pred, LL_pred, output_dict=True))
    report = pd.DataFrame(df)
    print("Classification Report - ", report)
    mse = metrics.mean_squared_error(y_pred,LL_pred)
    print("Mean Squared Error - ", mse)
    rmse = math.sqrt(mse)
    print("Root mean Squared Error - ",rmse)
    mean_auc_svc = cross_val_score(LL, x_true, y_true, n_jobs=-1, cv=kf, scoring='roc_auc').mean()
    print("Mean AUC_ROC Score - ", mean_auc_svc)
    return LogisticRegression()

def create_decision_tree_model():
    from sklearn.tree import DecisionTreeClassifier
    from sklearn import metrics
    # instantiate the DecisionTreeClassifier model with criterion entropy
    clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=8, random_state=8, splitter ='random')
    # fit the model
    clf_en.fit(x_true, y_true)
    y_pred_en = clf_en.predict(x_pred)
    from sklearn.metrics import accuracy_score
    y_pred_train_en = clf_en.predict(x_true)
    print('accuracy - ', (accuracy_score(y_true, y_pred_train_en)))
    mse = metrics.mean_squared_error(y_pred,y_pred_en)
    print("Mean Squared Error - ", mse)
    rmse = math.sqrt(mse)
    print("Root mean Squared Error - ",rmse)
    df = (classification_report(y_pred, y_pred_en, output_dict=True))
    report = pd.DataFrame(df)
    print("Classification Report - ", report)
    mean_auc_svc = cross_val_score(clf_en, x_true, y_true, n_jobs=-1, cv=kf, scoring='roc_auc').mean()
    print("Mean AUC_ROC Score - ", mean_auc_svc)
    return DecisionTreeClassifier()

def create_random_forest_model():
    rs = int(input("Select the value of random state"))
    ne = int(input("Select the value of n estimator"))
    from sklearn.ensemble import RandomForestClassifier
    from sklearn import metrics
    rfc = RandomForestClassifier(random_state=rs,n_estimators=ne)
    rfc.fit(x_true, y_true)
    rfcpred = rfc.predict(x_true)
    acc = accuracy_score(y_true, rfcpred)
    print("Accuracy - ", acc)
    mse = metrics.mean_squared_error(y_true,rfcpred)
    print("Mean Squared Error - ", mse)
    rmse = math.sqrt(mse)
    print("Root mean Squared Error - ",rmse)
    df = (classification_report(y_true, rfcpred, output_dict=True))
    report = pd.DataFrame(df)
    print("Classification Report - ", report)
    mean_auc_svc = cross_val_score(rfc, x_true, y_true, n_jobs=-1, cv=kf, scoring='roc_auc').mean()
    print("Mean AUC_ROC Score - ", mean_auc_svc)
    return RandomForestClassifier()

def create_support_vector_machine_model():
    from sklearn.svm import SVC
    from sklearn import metrics
    svc = SVC()
    svc.fit(x_true, y_true)
    from sklearn.metrics import accuracy_score
    svc_pred = svc.predict(x_pred)
    svc_train = svc.predict(x_true)
    accuracy = accuracy_score(y_true, svc_train)
    print("Accuracy - ", accuracy)
    s = metrics.confusion_matrix(y_pred, svc_pred)
    print("Confusion Matrix for pred Value - ", s)
    fig, ax = plt.subplots()
    sns.heatmap(s, ax = ax)
    st.write(fig)
    df = (classification_report(y_pred, svc_pred, output_dict=True))
    report = pd.DataFrame(df)
    print("Classification Report - ", report)
    mse = metrics.mean_squared_error(y_pred,svc_pred)
    print("Mean Squared Error - ", mse)
    rmse = math.sqrt(mse)
    print("Root mean Squared Error - ",rmse)
    mean_auc_svc = cross_val_score(svc, x_true, y_true, n_jobs=-1, cv=kf, scoring='roc_auc').mean()
    print("Mean AUC_ROC Score - ", mean_auc_svc)

    return SVC()

def KNN():
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn import metrics
    choice= input('"Choose the distance matrix" : euclidean,manhattan,minkowski')
    algo= input('"Choose the algorithm" : auto,ball_tree,kd_tree,brute')
    n_neighbors = int(input("Select Value of n_neigbours "))
    knn = KNeighborsClassifier(n_neighbors,metric=choice,algorithm=algo)
    knn.fit(x_true, y_true)
    knn_pred = knn.predict(x_pred)
    knn_train = knn.predict(x_true)
    error_rate=[]#list that will store the average error rate value of k
    for i in range (1,31):  #Took the range of k from 1 to 30
        clf=KNeighborsClassifier(n_neighbors=i,metric=choice,algorithm=algo)
        clf.fit(x_true,y_true)
        predict_i=clf.predict(x_true)
        error_rate.append(np.mean(predict_i!=y_true))
    x = np.array(error_rate)
    fig = plt.subplots()
    sns.lineplot(data=x)
    st.write(fig)
    print('accuracy_true = ', accuracy_score(y_true, knn_train))
    print('accuracy_pred = ', accuracy_score(y_pred, knn_pred))
    s = metrics.confusion_matrix(y_pred, knn_pred)
    print("Confusion Matrix for pred Value - ", s)
    fig, ax = plt.subplots()
    sns.heatmap(s, ax = ax)
    st.write(fig)
    df = (classification_report(y_pred, knn_pred, output_dict=True))
    report = pd.DataFrame(df)
    print("Classification Report - ", report)
    FP = s.sum(axis=0) - np.diag(s)
    FN = s.sum(axis=1) - np.diag(s)
    TP = np.diag(s)
    TN = s.sum() - (FP + FN + TP)
    FP = FP.astype(float)
    FN = FN.astype(float)
    TP = TP.astype(float)
    TN = TN.astype(float)
    # Sensitivity, hit rate, recall, or true positive rate
    TPR = TP/(TP+FN)
    # Specificity or true negative rate
    TNR = TN/(TN+FP)
    print("Sensitivity- ",TPR)
    print("Specificiity- ",TNR)
    mse = metrics.mean_squared_error(y_pred,knn_pred)
    print("Mean Squared Error - ", mse)
    rmse = math.sqrt(mse)
    print("Root mean Squared Error - ",rmse)
    mean_auc_svc = cross_val_score(knn, x_true, y_true, n_jobs=-1, cv=kf, scoring='roc_auc').mean()
    print("Mean AUC_ROC Score - ", mean_auc_svc)

def gaussian():
    from sklearn.naive_bayes import GaussianNB
    from sklearn import metrics
    gnb = GaussianNB()
    gnb.fit(x_true, y_true)
    pred = gnb.predict(x_pred)
    gnb_train = gnb.score(x_true, y_true)
    gnb_test = gnb.score(x_pred, y_pred)
    print('Train accuracy = ', gnb_train)
    print('Test accuracy  = ', gnb_test)
    df = (classification_report(y_pred, pred, output_dict=True))
    report = pd.DataFrame(df)
    print("Classification Report - ", report)
    mse = metrics.mean_squared_error(y_pred,pred)
    print("Mean Squared Error - ", mse)
    rmse = math.sqrt(mse)
    print("Root mean Squared Error - ",rmse)
    mean_auc_svc = cross_val_score(gnb, x_true, y_true, n_jobs=-1, cv=kf, scoring='roc_auc').mean()
    print("Mean AUC_ROC Score - ", mean_auc_svc)

def neural_net():
    from keras.models import Sequential
    from keras.layers import Dense
    from keras.utils import to_categorical
    import tensorflow as tf
    y_true=to_categorical(y_true)
    i=x_true.shape[1]
    model=Sequential()
    a = input("choose the first Activation Layer : 'relu','sigmoid','tanh'")
    b = input("choose the Second Activation Layer' : 'relu','sigmoid','tanh'")
    c = input("choose the Third Activation Layer : 'relu','sigmoid','tanh'")
    l = input("choose the Optimizer to be used : 'adam','adagrad','adadelta'")
    q= input("choose the Loss Function to be used : 'binary_crossentropy','categorical_crossentropy'")
    o = int(input('enter the number of epochs'))
    p = int(input('enter Batch Size'))
    x = 48
    model.add(Dense(12,input_dim=i,activation=a))
    model.add(Dense(8,activation=b))
    model.add(Dense(x,activation=c))
    model.compile(loss=q,optimizer=l,metrics=['accuracy'])

    history=model.fit(x_true,y_true,epochs=o,batch_size=p)
    from sklearn.metrics import accuracy_score
    y_pred=model.predict(x_pred)
    y_pred=np.argmax(y_pred,axis=1)
    print('accuracy score: {0:0.4f}'. format(accuracy_score(y_pred, y_pred)))
    import matplotlib.pyplot as plt
    fig ,ax = plt.subplots(figsize=(5,5))
    plt.plot(history.history['accuracy'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['Train'], loc='upper left')
    plt.show()


def main():
    print("Select a machine learning model:")
    print("1. Linear Regression")
    print("2. Logistic Regression")
    print("3. Decision Tree")
    print("4. Random Forest")
    print("5. Support Vector Machine")

    choice = int(input("Enter your choice (1/2/3/4/5): "))

    if choice == 1:
        model = create_linear_regression_model()
    elif choice == 2:
        model = create_logistic_regression_model()
    elif choice == 3:
        model = create_decision_tree_model()
    elif choice == 4:
        model = create_random_forest_model()
    elif choice == 5:
        model = create_support_vector_machine_model()
    elif choice == 6:
        model = KNN()
    elif choice == 7:
        model = gaussian()
    elif choice == 8:
        model = neural_net()
    else:
        print("Invalid choice")
        return

    # Now you can use the selected model for further processing
    print("Model created:", model)

if __name__ == "__main__":
    main()